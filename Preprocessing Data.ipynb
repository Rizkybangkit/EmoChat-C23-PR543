{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d99859a",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02503d65",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb28712",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19788197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset and extract MFCCs with segemnts\n",
    "def extract_mfcc_seg(name, path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \n",
    "    # Make a dictionary to store the data\n",
    "    data = {\n",
    "        'mfcc': [],\n",
    "        'label':[]\n",
    "    }\n",
    "    \n",
    "    # Loop through the folders\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        \n",
    "        # Process audio files\n",
    "        for file in filenames:\n",
    "            \n",
    "            # Check file type\n",
    "            if file.endswith('.wav'):\n",
    "                \n",
    "                # Save the semantic label\n",
    "                label = get_label(name, file)\n",
    "                \n",
    "                #print(\"\\nProcessing {} from: {}\".format(semantic_label, dirpath))\n",
    "                \n",
    "                if label is not None:\n",
    "\n",
    "                    # Load audio file\n",
    "                    file_path = os.path.join(dirpath, file)\n",
    "                    signal, sr = librosa.load(file_path, sr=4000)\n",
    "\n",
    "                    # Calculations\n",
    "                    duration = len(signal) / sr\n",
    "                    samples_per_track = 4000 / duration\n",
    "                    samples_per_segments = int(samples_per_track / num_segments)\n",
    "                    expected_mffc_amount = math.ceil(samples_per_segments / hop_length)\n",
    "\n",
    "                    # Process segments and extract MFCC\n",
    "                    for s in range(num_segments):\n",
    "                        start_sample = samples_per_segments * s\n",
    "                        finish_sample = start_sample + samples_per_segments\n",
    "\n",
    "                        # Extract MFCC\n",
    "                        mfcc = librosa.feature.mfcc(y=signal[start_sample:finish_sample],\n",
    "                                                    sr=sr,\n",
    "                                                    n_mfcc=n_mfcc,\n",
    "                                                    n_fft=n_fft,\n",
    "                                                    hop_length=hop_length\n",
    "                                                   )\n",
    "                        mfcc = mfcc.T\n",
    "\n",
    "                        # Store the MFCC\n",
    "                        if len(mfcc) == expected_mffc_amount:\n",
    "                            data['mfcc'].append(mfcc.tolist())\n",
    "                            data['label'].append(label)\n",
    "                            print(\"{}\\n{}, segment:{}\".format(label, mfcc, s))\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset and extract MFCCs without segments\n",
    "def extract_mfcc(name, path, n_mfcc=13, n_fft=2048, sr=44100):\n",
    "    \n",
    "    # Make a dictionary to store the data\n",
    "    data = {\n",
    "        'mfcc': [],\n",
    "        'label':[]\n",
    "    }\n",
    "    \n",
    "    # Loop through the folders\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        \n",
    "        # Process audio files\n",
    "        for file in filenames:\n",
    "            \n",
    "            # Check file type\n",
    "            if file.endswith('.wav'):\n",
    "                \n",
    "                # Save the semantic label\n",
    "                label = get_label(name, file)\n",
    "                \n",
    "                if label is not None:\n",
    "                    # Load audio file\n",
    "                    file_path = os.path.join(dirpath, file)\n",
    "                    signal, sr = librosa.load(file_path, sr=sr)\n",
    "\n",
    "                    # Extract MFCC for the entire audio file\n",
    "                    mfcc = librosa.feature.mfcc(y=signal,\n",
    "                                                sr=sr,\n",
    "                                                n_mfcc=n_mfcc,\n",
    "                                                n_fft=n_fft,\n",
    "                                               )\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # Store the MFCC\n",
    "                    data['mfcc'].append(mfcc.tolist())\n",
    "                    data['label'].append(label)\n",
    "                    print(\"{}\\n{}\".format(label, mfcc))\n",
    "                    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label data\n",
    "def get_label(name, data_label):\n",
    "    \n",
    "    # Check the dataset of the label\n",
    "    if name == 'ravdess':\n",
    "        label = data_label[7]\n",
    "        label_name = {\n",
    "            '1': 'neutral',\n",
    "            '2': 'calm',\n",
    "            '3': 'happy',\n",
    "            '4': 'sad',\n",
    "            '5': 'angry',\n",
    "            '6': 'fearful',\n",
    "            '7': 'disgust',\n",
    "            '8': 'surprised'\n",
    "        }\n",
    "        \n",
    "    elif name == 'crema':\n",
    "        label = data_label.split('_')[2]\n",
    "        label_name = {\n",
    "            'ANG': 'angry',\n",
    "            'DIS': 'disgust',\n",
    "            'FEA': 'fearful',\n",
    "            'HAP': 'happy',\n",
    "            'NEU': 'neutral',\n",
    "            'SAD': 'sad'\n",
    "        }\n",
    "        \n",
    "    elif name == 'savee':\n",
    "        label = data_label[0]\n",
    "        if label == 's':\n",
    "            label = data_label[0:2]\n",
    "            \n",
    "        label_name = {\n",
    "            'a': 'angry',\n",
    "            'd': 'disgust',\n",
    "            'f': 'fearful',\n",
    "            'h': 'happy',\n",
    "            'n': 'neutral',\n",
    "            'sa': 'sad',\n",
    "            'su': 'surprised'\n",
    "        }\n",
    "        \n",
    "    elif name == 'tess':\n",
    "        label = data_label.split('_')[2]\n",
    "        label_name = {\n",
    "            'angry.wav': 'angry',\n",
    "            'disgust.wav': 'disgust',\n",
    "            'fear.wav': 'fearful',\n",
    "            'happy.wav': 'happy',\n",
    "            'neutral.wav': 'neutral',\n",
    "            'ps.wav': 'surprised',\n",
    "            'sad.wav': 'sad'\n",
    "        }\n",
    "    \n",
    "    \"\"\"\"\n",
    "    Encode all labels\n",
    "    # Encode the label\n",
    "    label_encoding = {\n",
    "        'neutral': 0,\n",
    "        'calm': 1,\n",
    "        'happy': 2,\n",
    "        'sad': 3,\n",
    "        'angry': 4,\n",
    "        'fearful': 5,\n",
    "        'disgust': 6,\n",
    "        'surprised': 7\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Encode only 6 label\n",
    "    label_encoding = {\n",
    "        'neutral': 0,\n",
    "        'happy': 1,\n",
    "        'sad': 2,\n",
    "        'angry': 3,\n",
    "        'fearful': 4,\n",
    "        'disgust': 5,\n",
    "    }\n",
    "    \n",
    "    semantic_label = label_name.get(label)\n",
    "    num_label = label_encoding.get(semantic_label)\n",
    "    \n",
    "    return num_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87994a87",
   "metadata": {},
   "source": [
    "## RAVDESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path of the dataset\n",
    "ravdess_path = f\"{os.getcwd()}/ravdess\"\n",
    "\n",
    "# Load data\n",
    "ravdess_data = extract_mfcc('ravdess', ravdess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ravdess_data['mfcc'][18], ravdess_data['label'][18])\n",
    "len(ravdess_data['mfcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd8a62",
   "metadata": {},
   "source": [
    "## CREMA_D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a79b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "crema_path = f\"{os.getcwd()}/crema_d\"\n",
    "\n",
    "# Load data\n",
    "crema_data = extract_mfcc('crema', crema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(crema_data['mfcc'][7], crema_data['label'][7])\n",
    "len(crema_data['mfcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66034d",
   "metadata": {},
   "source": [
    "## SAVEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98698644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "savee_path = f\"{os.getcwd()}/savee\"\n",
    "\n",
    "# Load data\n",
    "savee_data = extract_mfcc('savee', savee_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa54808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(savee_data['mfcc'][7], savee_data['label'][7])\n",
    "len(savee_data['mfcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592403af",
   "metadata": {},
   "source": [
    "## TESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "tess_path = f\"{os.getcwd()}/tess\"\n",
    "\n",
    "# Load data\n",
    "tess_data = extract_mfcc('tess', tess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f22ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tess_data['mfcc'][7], tess_data['label'][7])\n",
    "len(tess_data['mfcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f90a0e",
   "metadata": {},
   "source": [
    "## Augmented RAVDESS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "aug_path = f\"{os.getcwd()}/augmented_data\"\n",
    "\n",
    "# Load data\n",
    "aug_data = extract_mfcc('ravdess', aug_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aug_data['mfcc'][7], aug_data['label'][7])\n",
    "len(aug_data['mfcc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40d699",
   "metadata": {},
   "source": [
    "## Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to save all the data\n",
    "data = {\n",
    "    'mfcc': [],\n",
    "    'label': []\n",
    "}\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ravdess data\n",
    "data['mfcc'].extend(ravdess_data['mfcc'])\n",
    "data['label'].extend(ravdess_data['label'])\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20148e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add crema data\n",
    "data['mfcc'].extend(crema_data['mfcc'])\n",
    "data['label'].extend(crema_data['label'])\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecf8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add savee data\n",
    "data['mfcc'].extend(savee_data['mfcc'])\n",
    "data['label'].extend(savee_data['label'])\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tess data\n",
    "data['mfcc'].extend(tess_data['mfcc'])\n",
    "data['label'].extend(tess_data['label'])\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c370ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add augmented data\n",
    "data['mfcc'].extend(aug_data['mfcc'])\n",
    "data['label'].extend(aug_data['label'])\n",
    "\n",
    "print(len(data['mfcc']), len(data['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc0c82",
   "metadata": {},
   "source": [
    "## Ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(json_path, data):\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the json file\n",
    "json_path = 'combined-data - 6 label.json'\n",
    "\n",
    "# Ouput json file\n",
    "save_json(json_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba6d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
